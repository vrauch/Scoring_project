{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-27T07:41:38.584949Z",
     "start_time": "2024-03-27T07:41:37.165296Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mjson\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mthreading\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdotenv\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_dotenv\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mglob\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mre\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import threading\n",
    "from dotenv import load_dotenv\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    " # Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI API key\n",
    "openai.api_key = os.getenv(\"OPENAI_KEY\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0c1d43c2ab99428"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def split_text(text, word_limit=1300):\n",
    "    \"\"\"\n",
    "    Splits a given text into chunks of a specific size.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The text to be split.\n",
    "    word_limit (int): The maximum size of each chunk.\n",
    "\n",
    "    Returns:\n",
    "    list: The list of chunks.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    num_parts = len(words) // word_limit + 1\n",
    "    return [' '.join(words[i * word_limit: (i + 1) * word_limit]) for i in range(num_parts)]\n",
    "\n",
    "def print_period():\n",
    "    \"\"\"\n",
    "    Prints a period character to the console every second. \n",
    "    Uses a global timer object to schedule itself to run every second.\n",
    "    \"\"\"\n",
    "    global period_timer\n",
    "    print(\".\", end=\"\", flush=True)\n",
    "    period_timer = threading.Timer(1.0, print_period)\n",
    "    period_timer.start()\n",
    "\n",
    "def load_prompt(filename=\"prompt.json\"):\n",
    "    \"\"\"\n",
    "    Loads a prompt from a JSON file.\n",
    "\n",
    "    Parameters:\n",
    "    filename (str): The name of the JSON file.\n",
    "\n",
    "    Returns:\n",
    "    list: The loaded prompt.\n",
    "    \"\"\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    lines = text.split('\\n')\n",
    "    processed_lines = [line for line in lines if not line.strip().startswith(tuple('0123456789')) and line.strip() != '']\n",
    "    return '\\n'.join(processed_lines)\n",
    "\n",
    "def create_summary(file_path, prompt):\n",
    "    \"\"\"\n",
    "    Creates a summary for a given file using the OpenAI GPT 3.5 Turbo API.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path of the file.\n",
    "    prompt (list): The prompt to use for the OpenAI API.\n",
    "\n",
    "    Returns:\n",
    "    str: The summary.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        print(f\"Reading {os.path.basename(file_path)}\")\n",
    "        transcript = f.read()\n",
    "\n",
    "    # Preprocess the transcript\n",
    "    transcript = preprocess_text(transcript)\n",
    "\n",
    "    chunks = split_text(transcript)\n",
    "    summary_list = []\n",
    "    total_chunks = len(chunks)\n",
    "\n",
    "    for i, chunk in enumerate(chunks, start=1):\n",
    "        prompt[-2][\"content\"] = chunk\n",
    "        retries = 0\n",
    "        while retries < 5:\n",
    "            try:\n",
    "                print(f\"Making summarization request {i}/{total_chunks} to OpenAI API for {os.path.basename(file_path)}\", end=\"\")\n",
    "                print_period()\n",
    "\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=prompt,\n",
    "                    max_tokens=300,\n",
    "                    temperature=0.6,\n",
    "                    n=1,\n",
    "                    stop=None\n",
    "                )\n",
    "                period_timer.cancel()\n",
    "                print(\"\")\n",
    "                summary = response.choices[0].message['content'].strip()\n",
    "                summary_list.append(summary)\n",
    "                break\n",
    "            except openai.error.RateLimitError:\n",
    "                print(\"\\nReceived rate limit error, waiting for 60 seconds before retrying...\")\n",
    "                period_timer.cancel()\n",
    "                time.sleep(60)\n",
    "                retries += 1\n",
    "            except Exception as e:\n",
    "                print(\"\\nQuitting due to unexpected error: {}\".format(e))\n",
    "                period_timer.cancel()\n",
    "                return None\n",
    "        if retries >= 5:\n",
    "            print(\"\\nExceeded maximum number of retries. Giving up on current chunk.\")\n",
    "    return '\\n'.join(summary_list)\n",
    "\n",
    "def save_summary(file_path, summary):\n",
    "    \"\"\"\n",
    "    Saves a summary to a file.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path of the file.\n",
    "    summary (str): The summary to save.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"w\") as f:\n",
    "        print(f\"Creating {os.path.basename(file_path)} in results directory\")\n",
    "        f.write(summary)\n",
    "\n",
    "\n",
    "def process_files(input_files, prompt):\n",
    "    \"\"\"\n",
    "    Processes a list of files.\n",
    "\n",
    "    Parameters:\n",
    "    input_files (list): The list of input files.\n",
    "    prompt (list): The prompt to use for the OpenAI API.\n",
    "    \"\"\"\n",
    "    for file_path in input_files:\n",
    "        output_file = os.path.join(\"results\", os.path.basename(file_path).replace(\".txt\", \"-summary.txt\"))\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"Output file {os.path.basename(output_file)} already exists, skipping.\")\n",
    "            continue\n",
    "        summary = create_summary(file_path, prompt)\n",
    "        if summary is not None:\n",
    "            try:\n",
    "                save_summary(output_file, summary)\n",
    "            except PermissionError:\n",
    "                print(f\"No permission to write file: {output_file}\")\n",
    "            except FileExistsError:\n",
    "                print(f\"File already exists: {output_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while writing the file: {output_file}. Error: {e}\")\n",
    "\n",
    "# Define the timer object as global so we can access it everywhere\n",
    "period_timer = None\n",
    "\n",
    "# Load the prompt\n",
    "prompt = load_prompt()\n",
    "\n",
    "# Get a list of all .txt files in the ./input directory\n",
    "input_files = glob.glob('./input/*.txt')\n",
    "\n",
    "if not input_files:\n",
    "    print(\"No text files found in the input directory.\")\n",
    "else:\n",
    "    process_files(input_files, prompt)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6896bb944a74b41f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
