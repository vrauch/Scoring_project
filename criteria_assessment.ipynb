{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "368a8578f16d9cb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "path = os.getenv('FILE_PATH')\n",
    "print(path)\n",
    "os.chdir(path)  # Change to your own path"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e927b10e6bf71c41",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sympy.codegen.ast import none\n",
    "\n",
    "# Load your spreadsheet data into a pandas DataFrame\n",
    "df = pd.read_excel('response_test.xlsx') #, sheet_name=\"DevOps\")\n",
    "df['Semantic Similarity Score'] = float('nan')\n",
    "#print(df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c99bae8801e5ccde",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Set your OpenAI API key (replace with your actual key)\n",
    "# openai.api_key = \"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\"\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "print(openai.api_key)\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=openai.api_key)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29571c96e4f14aee",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the model and tokenizer\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "290396cc154734d1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def analyze_alignment(capability, criteria, text):\n",
    "    # Create a prompt for the model\n",
    "    prompt1 = f\"\"\"You are trained to analyze and determine the alignment strength between the given criteria and text. If you are unsure of an answer, you can say \"not sure\" and recommend the user review manually. Analyze the following criteria and text pair and determine the alignment strength: Criteria: {criteria} Text: {text}\"\"\"\n",
    "    \n",
    "# Call the OpenAI API to generate a response\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a good assistant\"},\n",
    "            {\"role\": \"user\", \"content\": prompt1},\n",
    "        ],\n",
    "        max_tokens=100,\n",
    "        temperature=0\n",
    "    )\n",
    "    #print(prompt)\n",
    "    #print(response.choices[0].message)\n",
    "    alignment_strength = response.choices[0].message.content.strip().lower()\n",
    "    return alignment_strength\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "916bccdccdb5343e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_embedding(text, tokenizer, model):\n",
    "    # Tokenize and convert to input IDs\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    # Generate embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Use mean pooling to get a single vector representation\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    attention_mask = inputs['attention_mask']\n",
    "    mask_expanded = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(embeddings * mask_expanded, 1)\n",
    "    sum_mask = mask_expanded.sum(1)\n",
    "    sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "    mean_pooled = sum_embeddings / sum_mask\n",
    "    return mean_pooled"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d478804c10dfb76",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(criteria, text, tokenizer, model):\n",
    "    # Get embeddings for both texts\n",
    "    embedding1 = get_embedding(criteria, tokenizer, model).numpy().flatten()\n",
    "    embedding2 = get_embedding(text, tokenizer, model).numpy().flatten()\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    score = 1 - cosine(embedding1, embedding2)\n",
    "    return score"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50c082b79d747588",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def summarize_paragraph(single_summary):\n",
    "    # Use the completion endpoint to summarize the paragraph\n",
    "    response = openai.completions.create(\n",
    "      model=\"gpt-3.5-turbo-instruct\",\n",
    "      prompt=f\"You are an expert summarizer. Your task is to read the following assessments;{single_summary}, which contains a varied set of analyses, and summarize the main points in a short narrative paragraph. Focus on capturing the essence of the analyses, highlighting key findings, and presenting them in a clear, concise manner. Please ensure the summary is informative, easy to understand and writen in a positive tone.\",\n",
    "      max_tokens=1000,\n",
    "      temperature=.2,\n",
    "      user=\"role\" \"Expert summarizer\"  \n",
    "      #top_p=0.5,\n",
    "      #frequency_penalty=2,\n",
    "      #presence_penalty=0\n",
    "    )\n",
    "    \n",
    "    # Extract and return the summarized text from the response\n",
    "    return response.choices[0].text.strip()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb8699ca633252d3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Iterate over each Criteria in the DataFrame and perform analysis\n",
    "results = []\n",
    "similarity_scores = []\n",
    "for _, row in df.iterrows():\n",
    "    capability = row[\"Capability\"]\n",
    "    criteria = row['Criteria']\n",
    "    text = row['Text']\n",
    "    score = row['Semantic Similarity Score']\n",
    "    strength = analyze_alignment(capability, criteria, text)\n",
    "    \n",
    "    # semantic similarity - correlation analysis in textual data.\n",
    "    similarity = compute_cosine_similarity(criteria, text, tokenizer, model)\n",
    "    similarity = round(similarity,2)\n",
    "     # Append the similarity score to the similarity_scores list\n",
    "    similarity_scores.append(similarity)\n",
    "    \n",
    "    results.append([capability,criteria, text, strength, similarity]) \n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce771906f1523aa9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Write Domain Summary \n",
    "# Converting to string if they are not already\n",
    "for result in results:\n",
    "    result[3] = str(result[3])\n",
    "    #print(result[3])\n",
    "    \n",
    "# Extracting the 'strength' outputs from results\n",
    "result_join = [result[3] for result in results]\n",
    "single_summary = ' '.join(result_join)\n",
    "assessment = summarize_paragraph(single_summary)\n",
    "average_similarity = sum(similarity_scores) / len(similarity_scores) if similarity_scores else 0\n",
    "average_similarity = round(average_similarity, 2)\n",
    "\n",
    "# print (f'{assessment}, \\n\"Overall Similarity Score\" {average_similarity}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6151f92a365e7c6f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Print output - Use for testing\n",
    "#print(results)\n",
    "print (f'{assessment}, \\n\"Overall Similarity Score\" {average_similarity}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f94be85e66aeb461",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame(results, columns=['Capability', 'Criteria','Response', 'Alignment Strength', 'Semantic Similarity Score'])\n",
    "output_df.to_csv('alignment_results.csv', index=False)\n",
    "domain_summary = pd.DataFrame({\"Assessment\":[assessment], \"Score\": [average_similarity]})\n",
    "domain_summary.to_csv('domain_summary.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1ca66afff31f192",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2744eff62d9aa38f",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
